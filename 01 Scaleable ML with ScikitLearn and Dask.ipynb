{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scalable Machine Learning in Python \n",
    "===================\n",
    "with Scikit-Learn and Dask \n",
    "===============\n",
    "**August 2018**\n",
    "\n",
    "Ian Stokes-Rees [@ijstokes](http://twitter.com/ijstokes) \n",
    "[http://bit.ly/scaleml-dask-wkshp](http://bit.ly/scaleml-dask-wkshp)\n",
    "\n",
    "\n",
    "<a href=\"http://dask.pydata.org\" ><img src=\"http://dask.pydata.org/en/latest/_images/dask_stacked.svg\"\n",
    " width=200 />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Description\n",
    "\n",
    "This hands-on 3 hour workshop will give participants an opportunity to explore [Dask](http://dask.pydata.org), a parallel computing framework for Python.  We will start with an overview of Dask and the problem it was designed to address, and then look at three exercises that demonstrate the Dask parallel wrappers for [Pandas](http://pandas.pydata.org), [NumPy](http://www.numpy.org), and [Scikit-Learn](http://www.scikit-learn.org).\n",
    "\n",
    "<table>\n",
    "<tr><td>\n",
    "<a href=\"http://dask.pydata.org\" ><img src=\"http://dask.pydata.org/en/latest/_images/dask_stacked.svg\"\n",
    " width=200 />\n",
    "</a>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "<a href=\"http://scikit-learn.org/\" ><img src=\"http://scikit-learn.org/stable/_images/scikit-learn-logo-notext.png\"\n",
    " width=200 />\n",
    "</a>\n",
    "</td>\n",
    "<td>\n",
    "<a href=\"http://pandas.pydata.org\" ><img src=\"http://people.math.sc.edu/etpalmer/Images/pandas_logo.png\"\n",
    " width=200 />\n",
    "</a>\n",
    "<br/>\n",
    "<a href=\"http://www.numpy.org\" ><img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/8/82/Logo_of_NumPy.svg/1200px-Logo_of_NumPy.svg.png\"\n",
    " width=200 />\n",
    "</a>\n",
    "</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Presenter\n",
    "--------\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr><td>\n",
    "<font size=+2><b>Ian Stokes-Rees</b> [@ijstokes](http://twitter.com/ijstokes)\n",
    "<br/>[StokesRees.Ian@bcg.com](mailto:StokesRees.Ian@bcg.com)\n",
    "<br/>\n",
    "[http://about.me/ijstokes](http://about.me/ijstokes)\n",
    "<br/>\n",
    "[http://linkedin.com/in/ijstokes](http://linkedin.com/in/ijstokes)\n",
    "<br/></font>\n",
    "</td>\n",
    "<td>\n",
    "<a href=\"https://www.bcg.com/beyond-consulting/bcg-gamma/\"><img src=\"http://image-src.bcg.com/Images/BCGGamma_FullColor-1230x660_tcm9-170581.png\" width=400 />\n",
    "</a>\n",
    "</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Acknowledgements\n",
    "---------------\n",
    "Adapted from material created by:\n",
    "* [Matthew Rocklin](https://github.com/mrocklin)\n",
    "* [Ben Zaitlen](https://github.com/quasiben)\n",
    "* [Martin Durant](https://github.com/martindurant)\n",
    "* [Tom Augspurger](https://github.com/TomAugspurger)\n",
    "* [Min Ragan-Kelley](https://github.com/minrk)\n",
    "* [Olivier Grisel](https://github.com/ogrisel)\n",
    "\n",
    "In particular:\n",
    "* [SciPy 2018 Dask Tutorial](https://github.com/martindurant/dask-tutorial-scipy-2018)\n",
    "* [PyCon 2017 Parallel Data Analysis Tutorial](https://us.pycon.org/2017/schedule/presentation/189/)\n",
    "* [Dask Tutorial](https://github.com/dask/dask-tutorial)\n",
    "* [Dask Talk](http://matthewrocklin.com/slides/dask-short#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assets and Reference\n",
    "-------------------\n",
    "This presentation:\n",
    "* Anaconda Cloud: https://anaconda.org/ijstokes/scaleml-dask-wkshp\n",
    "* GitHub: https://github.com/ijstokes/scaleml-dask-wkshp\n",
    "\n",
    "The material is based on the BSD-3 open source Dask project, which is included in the Anaconda Distribution:\n",
    "* Docs: http://dask.pydata.org/\n",
    "* GitHub: https://github.com/dask/dask\n",
    "* Support: http://dask.pydata.org/en/latest/support.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Setup\n",
    "-----\n",
    "* [Download Anaconda 5.2 for Python 3.6](http://continuum.io/downloads)\n",
    "\n",
    "* Clone or download the GitHub repo for the workshop:\n",
    "```bash\n",
    "git clone https://github.com/ijstokes/scaleml-dask-wkshp.git\n",
    "```\n",
    "\n",
    "* Quick and dirty:\n",
    "```bash\n",
    "conda install dask=0.18.2 python-graphviz h5py\n",
    "# pray\n",
    "```\n",
    "\n",
    "* Clean: create a conda environment for the workshop:\n",
    "```bash\n",
    "conda update -n root conda\n",
    "conda create -n dasktut anaconda=5.2 python=3.6\n",
    "conda activate dasktut\n",
    "conda install dask=0.18.2 python-graphviz h5py\n",
    "```\n",
    "\n",
    "* If you use `virtualenv/pipenv` you're on your own\n",
    "\n",
    "* In a pinch, use the [PanGeo Jupyter Hub](http://pangeo.pydata.org/) server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.2\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "print(dask.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphviz (optional)\n",
    "--------\n",
    "Graphviz is used by Dask to produce graphical representations graphs in the notebook. It is an optional extra that you can install.\n",
    "\n",
    "Although graphviz and it's python bindings are included in the provided environment, you need extra libraries for it to work on your system, and what you need depends on your OS\n",
    "\n",
    "- **Linux:** get `graphviz` from your system package manager (`yum install graphviz`)\n",
    "- **OSX:** install `graphviz` with brew/macports (`brew install graphviz`)\n",
    "- **Windows:** install from https://graphviz.gitlab.io/_pages/Download/Download_windows.html, and\n",
    "set your `PATH` to be able to find the installed executable (`set %PATH%=%PATH%;C:\\path\\to\\graphviz`)\n",
    "\n",
    "See the [graphviz documentation](https://graphviz.gitlab.io/download/) for further information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "print(graphviz.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Before we start\n",
    "\n",
    "We need to get some data to work with.\n",
    "We are going to generate some [fake stock data](https://github.com/mrocklin/fakestockdata) by adding a bunch of points between real stock data points. This will take a few minutes the first time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# or do this from the command line with `python prep_data.py`\n",
    "%run ./prep_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take about 4-5 minutes to run, depending on conference WiFi and your disk speed.\n",
    "It will require 5 GB of storage, but that is mostly for randomly generated data (no download)\n",
    "\n",
    "NOTE: If you want to experiment with very large datasets edit the file and look for `def weather()` to generate a 17 GB `data/weather-big` data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introductions\n",
    "\n",
    "*Introduce yourself to the people on either side of you*\n",
    "\n",
    "There is only one of me, so you're going to need to rely on each other for help during exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Benefits\n",
    "\n",
    "* Out-of-the-box parallel data structures with parallel methods that have interfaces you're familiar with.  In particular, Dask-ified parallel versions of `numpy.ndarray` and `pandas.Dataframe`.\n",
    "* Ability to wrap existing code and make it auto-magically parallel (this part is pretty amazing)\n",
    "* Low level primitives so you can construct your own parallel data structures\n",
    "* Low level primitives so you can construct your own parallel algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 1.1: Daskified parallel NumPy ndarray\n",
    "Take 10 minutes to get setup and then run through these basic Dask operations to see how it provides data structures similar to a `numpy.array` or `pandas.dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.random.randint(size=(10,10), low=1, high=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[3,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "a = da.random.randint(size=(60,60), low=1, high=10, chunks=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dask does ***lazy evaluation*** so it is returning a reference to a delayed operation, not yet invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a[3,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`.compute()` is required to actually get back the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[3,10].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Same story for vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[3,15:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a[3,15:25].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# or regions/matrix\n",
    "a[3:5, 15:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a[3:5, 15:25].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Notice what type this gives you, once it is fully reified\n",
    "b = a[3:5, 10:20].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(a[3:5, 15:25].compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ... and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why should I care that Dask looks like NumPy?\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just the `dask.array` interface, which is a parallel wrapper around NumPy `numpy.ndarray`, covering about 90% of its functionality.  The point is to warm you up to the idea that Dask can be used to provide parallel versions of data structures you are already familiar with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"chunksize\" parameter: how Dask breaks up an \"ndarray\" for parallel processing\n",
    "----------------------\n",
    "The `chunksize` parameter tells Dask how big to make each sub-unit of a `dask.array`.  These sub-units can then be operated on in parallel.  Usually `chunksize` will be pretty big (tens of thousands of elements in total, maybe more) otherwise `dask.array` won't work efficiently and will be slower than the vanilla `numpy.ndarray` version.  We're using a small `chunksize` now so you can learn about Dask and observe the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ex 1.2 Try some computations on `dask.array` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now think more carefully about what `chunksize` means for this `dask.array` object: how many sub-units are there in the size $(60,60)$ object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $a' \\times a + 100$ -- think about what that means mathematically and then in terms of an efficient numerical algorithm to calculate it given the number of sub-units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b = a.T * a + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b[3:5,10:20].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the overall Dask data structure `b`, and then what the fancy-indexed slice view below is going to refer to.  Consider what you think `shape`, `dtype`, `chunksize` will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[3:5, 10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many \"chuncks\" are there in the the slice above?\n",
    "\n",
    "Now consider the same thing for this slight variation on the view.  Can you predict what half the matrix will look like given the last output?  How many chunks do you think there will be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[3:5, 15:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in `chunksize`.  This should give you some key insights into how Dask is implementing `dask.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b.max().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think a parallel implementation of this `max()` method looks like, collapsing along `axis=1` (collapsing columns, or calculating down columns)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.max(axis=1).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ex 1.3 Visualize Dask Task Graphs\n",
    "**Note:** These may not work for you.\n",
    "\n",
    "It depends on whether or not graphviz and python-graphviz have installed properly.\n",
    "\n",
    "If not you'll still be able to do all the exercises, you just won't be able to see the task graphs that Dask is creating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a.visualize() # a = randint(size=(60,60), chunks=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "b.visualize() # b = a.T * a + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ex 1.4 Dask DataFrame\n",
    "If you're familiar with the `pandas.dataframe` then the `dask.dataframe` is going to be easy to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdf = pd.read_csv(\"./data/nycflights/1990.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# may need to fix slashes in file path if you're on Windows\n",
    "import dask.dataframe as dd\n",
    "df = dd.read_csv(\"./data/nycflights/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac and Linux only\n",
    "!wc -l ./data/nycflights/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ex 1.5 DataFrame columns\n",
    "\n",
    "We need to read in our `dask.dataframe` again and this time we're going to do 2 extra things:\n",
    "\n",
    "* create a `Date` column through the `parse_dates` parameter, using the first 3 columns.\n",
    "* provide type hints, since type inferrence is based off the first part of the first `pandas.datafram` and these may not be correct, leading to later typing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(os.path.join('data', 'nycflights', '*.csv'),\n",
    "                 parse_dates={'Date': [0, 1, 2]},\n",
    "                 dtype={'TailNum': str,\n",
    "                        'CRSElapsedTime': float,\n",
    "                        'Cancelled': bool})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Origin.unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ex 1.6 Dataframe methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.ArrDelay.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.ArrDelay.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ArrDelay.mean().visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ex 1.7 Visualize Dataframe Method Task Graphs\n",
    "\n",
    "Think about what this task graph is telling you about distributed data and distributed data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# What is the departure delay for each day of the week?\n",
    "day_delay = df.groupby(\"DayOfWeek\").DepDelay.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_delay.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_delay.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
